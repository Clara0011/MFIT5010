{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import future\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TQDM is a progress bar library with good support for nested loops and Jupyter/IPython notebooks.\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and \n",
    "# statistical natural language processing for English written in the Python programming language.\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import random\n",
    "# from tensorflow import set_random_seed\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/wangxiaolin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/wangxiaolin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wangxiaolin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is merged using the methods below:\n",
    " - Follow these steps or run the shell script here: Preprocessing Script\n",
    " - Move the tar file to the directory where you want this data to be stored.\n",
    " - Open a terminal window and cd to the directory that you put aclImdb_v1.tar.gz in.gunzip -c aclImdb_v1.tar.gz | tar xopf -\n",
    " - cd aclImdb && mkdir movie_data \n",
    " - for split in train test; do for sentiment in pos neg; do for file in $split/$sentiment/*; do cat $file >> movie_data/full_${split}.txt; echo >> movie_data/full_${split}.txt; done; done; done;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_pos = pd.read_csv('/Users/wangxiaolin/Documents/HKUST Machine Learning/project/dataset/train_pos.csv')\n",
    "train_neg = pd.read_csv('/Users/wangxiaolin/Documents/HKUST Machine Learning/project/dataset/train_neg.csv')\n",
    "test_pos = pd.read_csv('/Users/wangxiaolin/Documents/HKUST Machine Learning/project/dataset/test_pos.csv')\n",
    "test_neg = pd.read_csv('/Users/wangxiaolin/Documents/HKUST Machine Learning/project/dataset/test_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column\n",
    "train_pos[\"sentiment\"] = \"1\"\n",
    "train_neg[\"sentiment\"] = \"0\"\n",
    "test_pos[\"sentiment\"] = \"1\"\n",
    "test_neg[\"sentiment\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the train positive and negative  \n",
    "train = [train_pos, train_neg]\n",
    "train = pd.concat(train, ignore_index = True)\n",
    "\n",
    "# combine the test positive and negative  \n",
    "test = [test_pos, test_neg]\n",
    "test = pd.concat(test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Review sentiment\n",
       "0           0  Bromwell High is a cartoon comedy. It ran at t...         1\n",
       "1           1  Homelessness (or Houselessness as George Carli...         1\n",
       "2           2  Brilliant over-acting by Lesley Ann Warren. Be...         1\n",
       "3           3  This is easily the most underrated film inn th...         1\n",
       "4           4  This is not the typical Mel Brooks film. It wa...         1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do Natural Language Processing tasks, we need to understand and be able to use regular expressions. The data needs to be cleaned before they are vecterized. Therefore, \n",
    " - the html content should be removed, \n",
    " - the non-alphabetic characters should be removed, \n",
    " - the sentences should be tokenized \n",
    " - and the word should be lemmatized to its lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in tqdm(data):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:58<00:00, 210.83it/s]\n",
      "100%|██████████| 25000/25000 [01:36<00:00, 260.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "#generate the cleaned data by calling the function above\n",
    "train[\"Review\"] = clean_data(train[\"Review\"])\n",
    "test[\"Review\"] = clean_data(test[\"Review\"])\n",
    "print(len(train[\"Review\"]))\n",
    "print(len(test[\"Review\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has to be converted into numeric representation so that the algorithm could understand them. This conversion is so called \"vectorization\" or \"one hot encoding\".\n",
    "\n",
    "Generally, we could created a large matrix with only one column for every unique word in the dataset (here, the reviews). Then the words in the review are transformed into one row containing 0s and 1s. Here, 1 stands for the fact that the word appears in this piece of review. We would expect each row of the matrix would contain mostly zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review = train.Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = test.Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangxiaolin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/wangxiaolin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_review)):\n",
    "    test_review[i]=' '.join(test_review[i])\n",
    "for i in range(len(train_review)):\n",
    "    train_review[i]=' '.join(train_review[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment = train.sentiment\n",
    "test_sentiment = test.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF Vecterization\n",
    "tfidf = TfidfVectorizer(min_df=5) #minimum document frequency of 5\n",
    "train_tfidf = tfidf.fit_transform(train_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We seperate the training set and the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_tfidf, train.sentiment, train_size = 0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.80096\n",
      "Accuracy for C=0.05: 0.8368\n",
      "Accuracy for C=0.25: 0.87552\n",
      "Accuracy for C=0.5: 0.88768\n",
      "Accuracy for C=1: 0.89232\n"
     ]
    }
   ],
   "source": [
    "# We select the best tuning parameter fist using the validation set for logistic regression model\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=1: 0.882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11041,  1491],\n",
       "       [ 1459, 11009]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# According to the results above, we choose C = 1\n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(train_tfidf, train_sentiment)\n",
    "lr_predictions = lr.predict(tfidf.transform(test_review))\n",
    "accuracy_score(predictions, test_sentiment)\n",
    "print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(predictions, test_sentiment)))\n",
    "metrics.confusion_matrix(predictions, test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the performance report for this model\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.88      0.88      0.88     12500\n",
      "    Negative       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_report=classification_report(test.sentiment,lr_predictions,target_names=['Positive','Negative'])\n",
    "print(lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the results:\n",
    "- we obtained an accuracy score of 0.882\n",
    "- Here, A precision of 0.88 suggests that among all reviews predicted to be positive, 88% of them are truly positive. \n",
    "- A recall of 0.88 indicates that among all truly positive claims, 88% of them are retrieved by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model - Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(train_tfidf, train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.70552\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(test.sentiment, dt.predict(tfidf.transform(test_review))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the performance report for this model\n",
    "dt_predict = dt.predict(tfidf.transform(test_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.71      0.71      0.71     12500\n",
      "    Negative       0.71      0.71      0.71     12500\n",
      "\n",
      "    accuracy                           0.71     25000\n",
      "   macro avg       0.71      0.71      0.71     25000\n",
      "weighted avg       0.71      0.71      0.71     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_report=classification_report(test.sentiment,dt_predict,target_names=['Positive','Negative'])\n",
    "print(dt_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the results:\n",
    "- we obtained an accuracy score of 0.70552\n",
    "- Here, A precision of 0.71 suggests that among all reviews predicted to be positive, 71% of them are truly positive.\n",
    "- A recall of 0.71 indicates that among all truly positive claims, 71% of them are retrieved by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(train_tfidf, train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8382\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(test.sentiment, rf.predict(tfidf.transform(test_review))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.83      0.85      0.84     12500\n",
      "    Negative       0.85      0.82      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We print the performance report for this model\n",
    "rf_predict = rf.predict(tfidf.transform(test_review))\n",
    "rf_report=classification_report(test.sentiment,rf_predict,target_names=['Positive','Negative'])\n",
    "print(rf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the results:\n",
    "- we obtained an accuracy score of 0.8382\n",
    "- Here, A precision of 0.83 suggests that among all reviews predicted to be positive, 83% of them are truly positive.\n",
    "- A recall of 0.85 indicates that among all truly positive claims, 85% of them are retrieved by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy scores for logistic regression model, decision tree model and random forest model are 0.882, 0.70552, and 0.8382 respectively. Therefore, the logistic regression model performs the best on the dataset according to the accuracy score. Same conclusion could be reached by checking the F1-score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
